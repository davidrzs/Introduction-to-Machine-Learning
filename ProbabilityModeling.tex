\section*{Probability modeling}
Find $h:X\rightarrow Y$ that min. pred. error: 
$R(h) = \int P(x,y)l(y;h(x)) \partial yx \partial y = \mathbb{E}_{x,y}[l(y;h(x))]$

\subsection*{For least squares regression}
Best $h$: $h^*(x) = \mathbb{E}[Y|X=x]$ \\
Pred.: $\hat{y} = \hat{\mathbb{E}}[Y|X=\hat{x}] = \int \hat{P}(y|X=\hat{x}) y \partial y$\\
\pseudosubsection{Equivalence Regularized \& Probabilistic}
For $C(w) = - \log P(w)$ and $l(w^Tx_i;x_i,y_i) = - \log P(y_i|x_i,w)$ we have 
$\argmin{w} \sum_{i=1}^{n} l (w^T x_i; x_i,y_i) + C(w) = \argmax{w} \prod_{i=1} P(y_i|x_i,w) \cdot P(w) =  \argmax{w} P(w|D)$\\
\pseudosubsection{MLE}
$\theta_{MLE} = \operatorname{argmax}_\theta ~ {P}(X| \theta) = \operatorname{argmax}_{\theta} \sum_i \log P(x_i|\theta)$ 
E.g. lin. + Gauss: $y_i = w^T x_i + \varepsilon_i, \varepsilon_i \sim \mathcal{N}(0, \sigma^2)$\\
i.e. $y_i \sim \mathcal{N}(w^T x_i, \sigma^2)$, With MLE (use\\ $\operatorname{argmin} ~ - \operatorname{log}$): $w^* = {\operatorname{argmin}_w} \sum (y_i-w^Tx_i)^2$\\
\pseudosubsection{MAP}
$\theta_{MAP} = \operatorname{argmax}_\theta ~ {P}(X| \theta) P(\theta) = \operatorname{argmax}_{\theta} \sum_i \log P(x_i|\theta) + \log P(\theta)$\\
\textit{Alternat. Notat.} $\argmax{_\theta } p(\theta) \prod_{i=1}^n p_{\theta}(y_i|x_i) $\\
\textit{Bay.:} $P(w|x,y) = \frac{P(w|x) P(y|x,w)}{P(y|x)} = \frac{P(w) P(y|x,w)}{P(y|x)}$\\
\pseudosubsection{Logistic regression}\\
Link func.: $\sigma(w^Tx) = \frac{1}{1+exp(-w^Tx)}$ (Sigmoid)\\
$P(y|x,w) = Ber(y; \sigma(w^Tx)) = \frac{1}{1+exp(-y w^T x)}$
Classification: Use $P(y|x,w)$, predict most likely class label.\\
MLE: ${\operatorname{argmax}_w} ~ P(y_{1:n}|w,x_{1:n})\\
\Rightarrow w^* ={\operatorname{argmin}}_w \sum_{i=1}^n log(1+exp(-y_i w^T x_i))$\\
SGD update: $w = w + \eta_t y x \hat{P}(Y = -y|w,x)$\\
$\hat{P}(Y = -y|w,x) = \frac{1}{1+exp(yw^Tx)}$\\
MAP: Gauss. prior $\Rightarrow ||w||_2^2$, Lap. p. $\Rightarrow||w||_1$\\
SGD: $w = w (1-2\lambda \eta_t) + \eta_t y x \hat{P}(Y = -y|w,x)$